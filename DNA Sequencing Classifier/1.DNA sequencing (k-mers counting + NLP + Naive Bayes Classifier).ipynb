{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  class\n",
       "0  ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...      4\n",
       "1  ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...      4\n",
       "2  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "3  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "4  ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...      3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data = pd.read_csv('human_data.txt', sep='\\t')     # pd.read_table     # Human data\n",
    "human_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some data for human DNA sequence coding regions and a class label.\n",
    "We also have data for Chimpanzee and a more divergent species, the dog.\n",
    "\n",
    "dataset can be downloaded from here : \n",
    "https://www.kaggle.com/thomasnelson/humandata/downloads/human_data.txt\n",
    "https://www.kaggle.com/thomasnelson/humandata/downloads/chimp_data.txt\n",
    "https://www.kaggle.com/thomasnelson/humandata/downloads/dog_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_data = pd.read_csv('chimp_data.txt', sep='\\t')   # Chimpanzee DNA Sequence data\n",
    "dog_data = pd.read_csv('dog_data.txt', sep='\\t')      # Dog DNA sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the definitions for each of the 7 classes and how many there are in the human training data.\n",
    "They are gene sequence function groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sequnce1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whenever we are working with DNA Sequence, Transcriptions we basically convert these as languages, in order to convert these into languages we use this, 'k-mer counting' technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treating DNA sequence as a \"language\", otherwise known as k-mer counting\n",
    "\n",
    "A challenge that remains is that none of these above methods results in vectors of uniform length, and that is a requirement \n",
    "for feeding data to a classification or regression algorithm. So with the above methods you have to resort to things like \n",
    "truncating sequences or padding with \"n\" or \"0\" to get vectors of uniform length.\n",
    "\n",
    "DNA and protein sequences can be viewed metaphorically as the language of life. The language encodes instructions as well as\n",
    "function for the molecules that are found in all life forms. The sequence language analogy continues with the genome as the\n",
    "book, subsequences (genes and gene families) are sentences and chapters, k-mers and peptides (motifs) are words, and \n",
    "nucleotide bases and amino acids are the alphabet. Since the analogy seems so apt, it stands to reason that the amazing work \n",
    "done in the natural language processing field should also apply to the natural language of DNA and protein sequences.\n",
    "\n",
    "****The method used here is simple and easy. first take the long biological sequence and break it down into k-mer length \n",
    "overlapping “words”.\n",
    "For example, if I use \"words\" of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. \n",
    "Hence our example sequence is broken down into 4 hexamer words.\n",
    "\n",
    "Here using hexamer 'words' but that is arbitrary and word length can be tuned to suit the particular situation. \n",
    "The word length and amount of overlap need to be determined empirically for any given application.\n",
    "In genomics, we refer to these types of manipulations as \"k-mer counting\", or counting the occurances of each possible \n",
    "k-mer sequence. There are specialized tools for this, but the Python natural language processing tools make it supe easy.\n",
    "Here is a function that can be used to convert any sequence (string) to overlapping k-mer words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the article link : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206409"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once they convert this type of sequence into a fixed length of sequences, then they will try to apply -> Bag of Word (or TF-IDF) and convert this into fix set of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a function to collect all possible overlapping k-mers of a specified length from any sequence string. We will basically apply the k-mers to the complete sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size=6):     # converting this 'sequence' into this size=6\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can convert our training data sequences into short overlapping k-mers of legth 6. Lets do that for each species of data we have using our getKmers function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['words'] = human_data.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "human_data = human_data.drop('sequence', axis=1)    # after converting into sequence into k-mers, dropping 'sequence' column \n",
    "\n",
    "chimp_data['words'] = chimp_data.apply(lambda x: getKmers(x['sequence']), axis=1)      # similarly for 'chimpanzee' data\n",
    "chimp_data = chimp_data.drop('sequence', axis=1)\n",
    "\n",
    "dog_data['words'] = dog_data.apply(lambda x: getKmers(x['sequence']), axis=1)   # also for 'dog' data\n",
    "dog_data = dog_data.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Now, our coding sequence data is changed to lowercase, split up into all possible k-mer words of length 6 and ready for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              words\n",
       "0      4  [atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...\n",
       "1      4  [atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...\n",
       "2      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "3      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "4      3  [atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use. We can also make a y variable to hold the class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_texts = list(human_data['words'])\n",
    "\n",
    "for item in range(len(human_texts)):\n",
    "    human_texts[item] = ' '.join(human_texts[item])      # 'human_texts' - input data \n",
    "    \n",
    "y_data = human_data.iloc[:, 0].values       # output 'class' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atgccc tgcccc gcccca ccccaa cccaac ccaact caacta aactaa actaaa ctaaat taaata aaatac aatact atacta tactac actacc ctaccg taccgt accgta ccgtat cgtatg gtatgg tatggc atggcc tggccc ggccca gcccac cccacc ccacca caccat accata ccataa cataat ataatt taatta aattac attacc ttaccc tacccc accccc ccccca ccccat cccata ccatac catact atactc tactcc actcct ctcctt tcctta ccttac cttaca ttacac tacact acacta cactat actatt ctattc tattcc attcct ttcctc tcctca cctcat ctcatc tcatca catcac atcacc tcaccc caccca acccaa cccaac ccaact caacta aactaa actaaa ctaaaa taaaaa aaaaat aaaata aaatat aatatt atatta tattaa attaaa ttaaac taaaca aaacac aacaca acacaa cacaaa acaaac caaact aaacta aactac actacc ctacca taccac accacc ccacct caccta acctac cctacc ctacct tacctc acctcc cctccc ctccct tccctc ccctca cctcac ctcacc tcacca caccaa accaaa ccaaag caaagc aaagcc aagccc agccca gcccat cccata ccataa cataaa ataaaa taaaaa aaaaat aaaata aaataa aataaa ataaaa taaaaa aaaaaa aaaaat aaaatt aaatta aattat attata ttataa tataac ataaca taacaa aacaaa acaaac caaacc aaaccc aaccct accctg ccctga cctgag ctgaga tgagaa gagaac agaacc gaacca aaccaa accaaa ccaaaa caaaat aaaatg aaatga aatgaa atgaac tgaacg gaacga aacgaa acgaaa cgaaaa gaaaat aaaatc aaatct aatctg atctgt tctgtt ctgttc tgttcg gttcgc ttcgct tcgctt cgcttc gcttca cttcat ttcatt tcattc cattca attcat ttcatt tcattg cattgc attgcc ttgccc tgcccc gccccc ccccca ccccac cccaca ccacaa cacaat acaatc caatcc aatcct atccta tcctag\n"
     ]
    }
   ],
   "source": [
    "print(human_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for Chimpanzee and Dog dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_texts = list(chimp_data['words'])\n",
    "for item in range(len(chimp_texts)):\n",
    "    chimp_texts[item] = ' '.join(chimp_texts[item])         # input\n",
    "y_chimp = chimp_data.iloc[:, 0].values                       # output \n",
    "\n",
    "dog_texts = list(dog_data['words'])\n",
    "for item in range(len(dog_texts)):\n",
    "    dog_texts[item] = ' '.join(dog_texts[item])     # input\n",
    "y_dog = dog_data.iloc[:, 0].values                 # output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Applying the BAG of WORDS using CountVectorizer using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model using CountVectorizer()\n",
    "# This is equivalent to k-mer counting\n",
    "# The n-gram size of 4 was previously determined by testing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(4,4))\n",
    "X = cv.fit_transform(human_texts)\n",
    "\n",
    "X_chimp = cv.transform(chimp_texts)\n",
    "X_dog = cv.transform(dog_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 232414)\n",
      "(1682, 232414)\n",
      "(820, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)              # It has many columns Bcoz each vector converted into columns.  \n",
    "print(X_chimp.shape)\n",
    "print(X_dog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have a look at class balance we can see we have relatively balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9653c12438>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_data['class'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split tha dataset : train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the human dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_data, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 232414)\n",
      "(876, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      "\n",
      "Predicted   0    1   2    3    4   5    6\n",
      "Actual                                   \n",
      "0          99    0   0    0    1   0    2\n",
      "1           0  104   0    0    0   0    2\n",
      "2           0    0  78    0    0   0    0\n",
      "3           0    0   0  124    0   0    1\n",
      "4           1    0   0    0  143   0    5\n",
      "5           0    0   0    0    0  51    0\n",
      "6           1    0   0    1    0   0  263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "print(\"Confusion matrix : \\n\")\n",
    "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : 98.40% \n",
      "\n",
      "Precision is : 98.43% \n",
      "\n",
      "Recall is : 98.40% \n",
      "\n",
      "f1_Score is : 98.40%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy Score is : {accuracy:0.2%} \\n')\n",
    "print(f'Precision is : {precision:0.2%} \\n')\n",
    "print(f'Recall is : {recall:0.2%} \\n')\n",
    "print(f'f1_Score is : {f1:0.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
